{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "Why this tutorial will be useful:\n",
    "- This tutorial builds on previous exercises to expand your data science toolkit\n",
    "- You will learn a handful of key techniques for visualizing high-dimensional data\n",
    "- <font color='green'>As previously, you will solely need to change the code at positions marked with ```# <- adapt code here```</font>, however you are encouraged to experiment further\n",
    "\n",
    "Main purpose of tutorial:\n",
    "- Give exposure to popular techniques for qualitatively presenting relationships in high-dimensional datasets\n",
    "- Provide visualization techniques that will be valuable in your own analyses\n",
    "\n",
    "Additional purposes of tutorial:\n",
    "- Give an overview of Principal Components Analysis (PCA), nonlinear correlation, and hierarchical clustering\n",
    "- Learn to identify outlier samples in high-dimensional data\n",
    "\n",
    "Stages:\n",
    "- Stage 0: Load necessary components\n",
    "- Stage 1: PCA (and plotting)\n",
    "- Stage 2: Plotting Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 0: Load necessary components\n",
    "\n",
    "Refer to \"02_homework\" for a review of the basics of data and package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import expression data\n",
    "counts = pd.read_csv(\"/Users/rogangrant/Box/chaperome_student_course/chaperome_class/homework/Human.RPKM.txt\",\n",
    "                    sep = \" \") # <- adapt code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will note that the gene identifiers are in ensembl format. The benefit of this is that these gene IDs will **never** change, whereas common gene names are highly variable and follow no clear convention. For the purposes of presenting data, however, most will prefer common gene names. For this exercise, we will substitute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move ensembl IDs into a column for merging\n",
    "counts = counts.reset_index()\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion\n",
    "# import conversion table\n",
    "gene_conversions = pd.read_csv(\"/Users/rogangrant/Box/chaperome_student_course/chaperome_class/homework/human_gene_name_conversions.csv\") # <- adapt code here\n",
    "name_conversions = gene_conversions[[\"ensembl_gene_id\", \"external_gene_name\"]]\n",
    "name_conversions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform merge\n",
    "counts = pd.merge(counts,\n",
    "                 name_conversions,\n",
    "                 left_on = \"index\",\n",
    "                 right_on = \"ensembl_gene_id\",\n",
    "                 how = \"inner\") #take intersection of datasets\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessary columns\n",
    "counts = counts.set_index(\"external_gene_name\")\n",
    "counts = counts.drop([\"index\", \"ensembl_gene_id\"], axis = 1) #axis = 1 selects columns\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: PCA (and plotting)\n",
    "\n",
    "Now that we have our data in a workable format, we can perform principal components analysis. Volumes have been written on this technique, and with good reason; it is extremely powerful for handling high-dimensional data. Back in the days of qPCR, experiments would generate expression data for just a few genes. If you want to compare patterns of expression for a group of samples for just two genes, the procedure is very simple: plot expression of gene A on the X-axis, and gene B on the Y-axis for each sample. A third gene could even go on the Z-axis for a 3D plot. RNA-seq, on the other hand, generates data for every transcript in the human genome (43256, in this case). Plotting this number of dimensions is effectively impossible in our 3-dimensional universe. \n",
    "\n",
    "How do we get past this? One option is to plot each dimension (gene) individually, but this is fairly tedious. We will see how this is made more possible with heatmaps later. Alternatively, we can reduce the dimensionality of our data. While this clearly has the risk of reducing information value (and certainly does, to some degree), this turns out to be an excellent way to compare high-dimensional datasets in a semi-quantitative way. Without going too far into the linear algebra, PCA identifies features (genes, in this case) which are highly correlated, and groups them together into a single \"principal component\". This is often referred to an eigenvector, which is the linear combination of these features into a single \"eigenfeature\". PCA then iteratively generates additional principal components from groups of features that are correlated, but orthogonal (not correlated) to existing principal components. Convention is generally to generate 2-3 principal components.\n",
    "\n",
    "This works particularly well with gene expression data, because groups of genes are often co-regulated. By examining the contribution of each gene to each eigenvector (or \"eigengene\", if you will), one can even begin the infer the biological significance. Most simply, however, PCA offers an excellent way to roughly compare the relationship between datasets for a given experiment. By examining how the samples cluster together on a PCA plot, we can better understand which samples behave similarly.\n",
    "\n",
    "Let's try this with the complete human dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1.1: pre-processing and PCA calculation\n",
    "\n",
    "To perform PCA, we need to manipulate the expression matrix in the following ways:\n",
    "1. Transpose the dataset, or flip it so that genes are columns, and samples are rows\n",
    "2. Scale expression values so that they vary from 0 to 1 and contribute equally to the PCA\n",
    "3. Center expression values about 0 (this is performed implicitly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose\n",
    "counts_for_pca = counts.transpose()\n",
    "counts_for_pca = counts_for_pca.rename_axis([\"sample\"])\n",
    "counts_for_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale from 0 to 1\n",
    "counts_for_pca_scaled = StandardScaler().fit_transform(counts_for_pca)\n",
    "\n",
    "# center and perform PCA\n",
    "pca = PCA(n_components=3) # we will do 3 PCs\n",
    "PCs = pca.fit_transform(counts_for_pca_scaled)\n",
    "pca_dataframe = pd.DataFrame(data = PCs,\n",
    "                           columns = ['PC1', 'PC2', 'PC3'])\n",
    "pca_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1.2: visualization \n",
    "\n",
    "Now that we have our PCA data, let's add our metadata and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add metadata\n",
    "\n",
    "pca_dataframe[\"sample\"] = counts_for_pca.index\n",
    "#make sample names match larger dataset (which includes a species prefix)\n",
    "for i in range(pca_dataframe[\"sample\"].size):\n",
    "    pca_dataframe[\"sample\"][i] = \"Human.\" + pca_dataframe[\"sample\"][i]\n",
    "\n",
    "md = pd.read_csv(\"/Users/rogangrant/Box/chaperome_student_course/chaperome_class/homework/Kaessman_sample_metadata.csv\") # <- adapt code here\n",
    "pca_dataframe = pd.merge(pca_dataframe,\n",
    "                        md,\n",
    "                        on = \"sample\",\n",
    "                        how = \"inner\")\n",
    "pca_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scatter\n",
    "sns.scatterplot(data = pca_dataframe,\n",
    "                x = \"PC1\",\n",
    "                y = \"PC2\",\n",
    "               hue = \"tissue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = pca_dataframe,\n",
    "                x = \"PC2\",\n",
    "                y = \"PC3\",\n",
    "               hue = \"tissue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, samples corresponding to a single tissue cluster together, as do similar tissues. It does appear that some testis samples may have been mishandled or differently processed in some way, as evidenced by their strange behavior on PC1. For more interesting visualization, try this for a tissue of interest for all organisms in the dataset. The trends are quite revealing.\n",
    "\n",
    "You can also try changing which factors you map to \"hue\", or you can include a \"style\" aesthetic, which will map a factor to the shape of a point. Try using \"age\" as a mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Plotting heatmaps\n",
    "\n",
    "In the simplest sense, heatmaps are just visualizations of a matrix. The rows and columns are the same, and the color or intensity of a given sample corresponds to its value. In general, brighter colors correspond to higher values, whereas \"cooler\" colors correspond to lower values. \n",
    "\n",
    "It is quite common to \"cluster\" rows and/or columns, such that more similar samples are organized together; this allows for better pattern recognition. While many clustering methods exist, they are all similar in principle. First, pairwise \"distances\" are calculated for each sample. This can be anything from correlation coefficients, to average differences between measurements, and depends largely on the type of data and the comparison. In all cases, the most similar datasets are identified iteratively, and joined in reverse, stepwise order until all datasets have been joined. This then gives an approximation of dataset similarity. By sorting the samples in order of similarity, much more obvious patterns tend to emerge. We will see this firsthand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2.1: average expression values by condition\n",
    "\n",
    "As with any good biological dataset, we have many replicates per sample. In order to reduce the complexity of our plot, we will average expression for each condition. As before, consider what impact a mean may have on these representations, as compared to median or other statistics.\n",
    "\n",
    "To do this, we will have to derive a new matrix from our raw data, with just one column per sample. Have a look at the old matrix as necessary to get an idea of how this will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, make the new column names, which will be the unique values after stripping replicate number\n",
    "mean_cols = list(counts.columns)\n",
    "regex = re.compile('\\.\\d+$') #i.e. \".[one or more digits][end of string]\"\n",
    "for i in range(len(mean_cols)):\n",
    "    mean_cols[i] = mean_cols[i][0:regex.search(mean_cols[i]).start()] #remove the regex shown above\n",
    "mean_cols = np.unique(mean_cols)\n",
    "mean_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create an empty data frame that we will fill with mean values\n",
    "mean_counts = pd.DataFrame(columns = mean_cols, index = counts.index)\n",
    "mean_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will iterate through each condition and get the mean expression value for each gene\n",
    "for condition in mean_cols:\n",
    "    #first, get the column names of all replicates for a given condition\n",
    "    replicates = []\n",
    "    for column in counts.columns:\n",
    "        if column.startswith(condition):\n",
    "            replicates.append(column)\n",
    "    \n",
    "    #then create a subset of counts with just those columns\n",
    "    subset = counts[replicates]\n",
    "    \n",
    "    #now take the mean value of every row\n",
    "    column_means = subset.apply(\n",
    "    np.mean, \n",
    "    axis='columns')\n",
    "    \n",
    "    #and place these means in our means dataframe\n",
    "    mean_counts[condition] = column_means\n",
    "    \n",
    "mean_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a matrix of mean expression values. You can adapt this code as you please to summarize your own subsets. Try performing a PCA on this dataset if you have time. Do the mean values recapitulate the patterns you observed above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2.2: Plot heatmap\n",
    "\n",
    "This section should be fairly straightforward. One important thing to consider, however, is how you will scale your values (if at all). Because some genes are expressed at very high levels, data for low-expression genes will likely be difficult to interpret due to the wide range of the color scale. Similar issues may also occur at the higher end.\n",
    "\n",
    "Some common solutions to this problem:\n",
    "1. Log2-transform all of the values\n",
    "2. Plot z-scores for each gene $Z_i = \\frac{ExpressionValue_i_ - Mean_gene.x_}{SD_gene.x_}$\n",
    "\n",
    "We will leave it up to you to try these operations and see what best captures the trends in your data. For now, we will just plot raw values, and we will do it without clustering.\n",
    "\n",
    "Note: we will just do this for the first 100 genes, but you will need to perform your own subsetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,25) #change this to accommodate large plot\n",
    "example_subset = mean_counts.iloc[0:99,:]\n",
    "sns.heatmap(data = example_subset, \n",
    "            robust = True) #robust sets the color scale to more realistic values for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually worked fairly well, so we can proceed without any transformations (at least for the sake of this example). You are encouraged to try to find the best normalization technique for your dataset. Now, how will this plot change if we cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(data = example_subset, \n",
    "               method=\"ward\",\n",
    "               robust = True,\n",
    "              figsize=[20,25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we have used Ward's Method for clustering, which is a popular method in the data science field. In the simplest sense, this groups samples with a minimal pairwise variance. Wikipedia is a great resource for further reading on Ward's Method, and hierchical clustering, in general.\n",
    "\n",
    "What we learn from this plot, as opposed to the unclustered plot above, is that our samples group very well by tissue, as would be expected. This is impressive, given that small number of genes included. It also nicely complements the results from the PCA, such as the significant overlap between brain (cerebrum) and cerebellum.\n",
    "\n",
    "We can also observe interesting gene groupings, which may reveal potential regulons (groups of co-expressed genes). Many \"housekeeping\" genes are observed in the high-expression group at the bottom, whereas tightly regulated genes such as HOXA11 fall into the \"dark\" cluster. See what trends you can identify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Hopefully this tutorial has served as a nice complement to homework 2, and has given some ideas of how to best represent high-dimensional data. This is just a short overview of the methods available, but PCA and cluster-/heat-mapping will almost always be included in transcriptomic data analysis. For higher level analysis, new multi-dimensional scaling and plotting methods are emerging, such as T-SNE and UMAP. Machine learning is also becoming increasingly popular for pattern identification in high-dimensional data. These are all outside of the scope of this module, but interested students are encouraged to read further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
